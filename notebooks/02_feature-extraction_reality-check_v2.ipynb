{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config 1: Intercept-ResNet-V2\n",
    "# Path config\n",
    "#INPUT_PATH = \"../data/raw/\"\n",
    "#IMAGE_PATH = INPUT_PATH + 'reality_check/'\n",
    "#OUTPUT_IMAGE_PATH = \"../data/interim/aida-image-captioning_inceptresnetv2_reality-check_v2/Images/\"\n",
    "#MODEL1 = tf.keras.applications.inception_resnet_v2\n",
    "# MODEL2 = tf.keras.applications.InceptionResNetV2(\n",
    "#TARGET_SIZE = (299, 299)\n",
    "\n",
    "# Config 2: InterceptV3\n",
    "INPUT_PATH = \"../data/raw/\"\n",
    "IMAGE_PATH = INPUT_PATH + 'reality_check/'\n",
    "OUTPUT_PATH = \"../data/interim/aida-image-captioning_inceptionv3_reality-check_v2/\"\n",
    "OUTPUT_IMAGE_PATH = OUTPUT_PATH + \"Images/\"\n",
    "MODEL1 = tf.keras.applications.inception_v3\n",
    "MODEL2 = tf.keras.applications.InceptionV3\n",
    "TARGET_SIZE = (299, 299)\n",
    "\n",
    "# GPU/CPU config\n",
    "MEMORY_OF_GPU = 6000  # MBytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: During GPU handling.\n",
      "1 Physical GPU, 2 Logical GPUs\n",
      "\n",
      "WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:ParameterServerStrategy (CentralStorageStrategy if you are using a single machine) with compute_devices = ['/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'], variable_device = '/device:CPU:0'\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "\n",
      "Runtime Context: 1-GPU\n",
      "Recommended Batch Size: 1024 datasets\n"
     ]
    }
   ],
   "source": [
    "# To get access to a GPU instance you can use the `change runtime type` and set the option to `GPU` from the `Runtime` tab  in the notebook\n",
    "# Checking the GPU availability for the notebook\n",
    "#tf.test.gpu_device_name()\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Create virtual GPUs\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            #OK, but solwer: \n",
    "            #gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "            #      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "            #      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "            #      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024)],\n",
    "            #OK\n",
    "            gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=MEMORY_OF_GPU//2),\n",
    "                      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=MEMORY_OF_GPU//2)],\n",
    "            #Error using NCCL automatically on mirrored strategy: gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10*1024)],\n",
    "        )\n",
    "\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            #OK, but solwer: \n",
    "            #gpus[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "            #      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "            #      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "            #      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024)],\n",
    "            #OK \n",
    "            gpus[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=MEMORY_OF_GPU//2),\n",
    "                      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=MEMORY_OF_GPU//2)],\n",
    "            #Error using NCCL automatically on mirrored strategy: gpus[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10*1024)],            \n",
    "        )\n",
    "    except:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(\"Warning: During GPU handling.\")\n",
    "        pass\n",
    "    finally:\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\\n\")\n",
    "\n",
    "# Set runtime context and batch size\n",
    "l_rtc_names = [\n",
    "    \"multi-GPU_MirroredStrategy\",\n",
    "    \"multi-GPU_CentralStorageStrategy\",\n",
    "    \"1-GPU\",\n",
    "    \"CPUs\",\n",
    "    \"multi-GPU_MirroredStrategy_NCCL-All-Reduced\",\n",
    "]\n",
    "l_rtc = [\n",
    "    tf.distribute.MirroredStrategy().scope(),\n",
    "    tf.distribute.experimental.CentralStorageStrategy().scope(),\n",
    "    tf.device(\"/GPU:0\"),\n",
    "    tf.device(\"/CPU:0\"),\n",
    "    tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.NcclAllReduce()).scope(),\n",
    "]\n",
    "if len(gpus) == 0:\n",
    "    rtc_idx = 3\n",
    "    batch_size = 64\n",
    "\n",
    "elif len(gpus) == 1:\n",
    "    rtc_idx = 2\n",
    "    batch_size = 4*256\n",
    "\n",
    "elif len(gpus) > 1:\n",
    "    rtc_idx = 0\n",
    "    batch_size = 8*256\n",
    "\n",
    "runtime_context = l_rtc[rtc_idx]\n",
    "\n",
    "print(f\"\\nRuntime Context: {l_rtc_names[rtc_idx]}\")\n",
    "print(f\"Recommended Batch Size: {batch_size} datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ths/miniconda3/envs/aida/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Set display option\n",
    "pd.set_option('display.max_colwidth',-1) # Set the max column width to see the complete caption\n",
    "\n",
    "# Set image to predict\n",
    "df = pd.DataFrame(data=[\"historical.jpg\", \"rae.jpg\", \"ths.jpg\", \"2662262499_3cdf49cedd.jpg\"], columns=[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "#datagen = ImageDataGenerator(rescale=1./255)  # not necessary anymore\n",
    "datagen = ImageDataGenerator()  # not necessary anymore\n",
    "pred_generator = datagen.flow_from_dataframe(dataframe=df,\n",
    "                                            directory=IMAGE_PATH, \n",
    "                                            x_col=\"image\", y_col=\"image\", \n",
    "                                            class_mode=\"raw\", \n",
    "                                            target_size=TARGET_SIZE,\n",
    "                                            shuffle=False\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model = MODEL2(\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input = image_model.input\n",
    "hidden_layer = image_model.layers[-1].output\n",
    "image_features_extract_model = tf.keras.Model(new_input, hidden_layer)\n",
    "#image_features_extract_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: das Verzeichnis »../data/interim/aida-image-captioning_inceptionv3_reality-check_v2/“ kann nicht angelegt werden: Die Datei existiert bereits\n",
      "mkdir: das Verzeichnis »../data/interim/aida-image-captioning_inceptionv3_reality-check_v2/Images/“ kann nicht angelegt werden: Die Datei existiert bereits\n"
     ]
    }
   ],
   "source": [
    "!mkdir $OUTPUT_PATH\n",
    "!mkdir $OUTPUT_IMAGE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (4, 299, 299, 3)\n",
      "img.shape: (4, 299, 299, 3)\n",
      "batch_features.shape: (4, 64, 2048)\n",
      "reshaped batch_features.shape: (4, 64, 2048)\n",
      "filename: ../data/interim/aida-image-captioning_inceptionv3_reality-check_v2/Images/historical.npy\n",
      "filename: ../data/interim/aida-image-captioning_inceptionv3_reality-check_v2/Images/rae.npy\n",
      "filename: ../data/interim/aida-image-captioning_inceptionv3_reality-check_v2/Images/ths.npy\n",
      "filename: ../data/interim/aida-image-captioning_inceptionv3_reality-check_v2/Images/2662262499_3cdf49cedd.npy\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-262eadaa51cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_IMAGE_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"filename: {filename}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aida/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aida/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aida/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1435\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "rtx_idx = 3\n",
    "runtime_context = l_rtc[rtc_idx]\n",
    "with runtime_context:\n",
    "    i=0\n",
    "    for X, _ in pred_generator:\n",
    "        img = MODEL1.preprocess_input(X)\n",
    "        batch_features = image_features_extract_model(img)\n",
    "        batch_features = tf.reshape(batch_features,\n",
    "                                    (batch_features.shape[0], -1, batch_features.shape[3]))\n",
    "        if i == 0:\n",
    "            print(f\"X.shape: {X.shape}\")\n",
    "            print(f\"img.shape: {img.shape}\")\n",
    "            print(f\"batch_features.shape: {batch_features.shape}\")\n",
    "            print(f\"reshaped batch_features.shape: {batch_features.shape}\")\n",
    "\n",
    "        for bf in batch_features:\n",
    "            filename = OUTPUT_IMAGE_PATH + df.iloc[i].image.replace(\".jpg\",\".npy\")\n",
    "            print(f\"filename: {filename}\")\n",
    "            np.save(filename, bf.numpy())\n",
    "            i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
